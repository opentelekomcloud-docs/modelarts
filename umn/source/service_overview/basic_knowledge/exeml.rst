.. _modelarts_01_0016:

ExeML
=====

To implement AI in various industries, AI model development must be simplified. Currently, only a few algorithm engineers and researchers are capable of AI development and optimization. They find it challenging to develop related prototypes into products and projects. Most service developers, however, face difficulties in developing AI algorithms and optimizing parameters. As a result, most enterprises lack comprehensive AI development capabilities.

ModelArts provides ExeML for service developers who are not experienced in algorithm development to develop algorithms. It automatically generates models based on transfer learning and Neural Architecture Search (NAS), selects parameters for model training, and tunes models for rapid model training and deployment. Based on the labeled data and application scenario provided by developers, ModelArts automatically generates models that meet precision requirements, without the need for coding. The application scenarios include image classification and object detection. Models can be automatically optimized and generated based on the deployment environment and inference speed requirements.

.. _modelarts_01_0016__en-us_topic_0284258742_en-us_topic_0168462757_fig3430158114210:

.. figure:: /_static/images/en-us_image_0000001214778791.png
   :alt: **Figure 1** Process of using ExeML


   **Figure 1** Process of using ExeML

ModelArts ExeML also provides the auto learning white-box capabilities. It opens model parameters and implements template-based development. ExeML helps accelerate the development speed. With ExeML, developers can directly optimize the generated model or retrain the model, instead of setting up a new model.

The key techniques of automatic deep learning are transfer learning (generating high-quality models based on a small amount of data), automatic design of the model architecture in multiple dimensions (neural network search and adaptive model optimization), and fast, accurate automatic tuning of training parameters.
