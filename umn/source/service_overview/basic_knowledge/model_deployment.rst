:original_name: modelarts_01_0015.html

.. _modelarts_01_0015:

Model Deployment
================

Generally, AI model deployment and large-scale implementation are complex.

ModelArts resolves this issue by deploying a trained model on different devices in various scenarios with only a few clicks. This secure and reliable one-stop deployment is available for individual developers, enterprises, and device manufacturers.


.. figure:: /_static/images/en-us_image_0000001110920824.png
   :alt: **Figure 1** Process of deploying a model

   **Figure 1** Process of deploying a model

-  The real-time inference service features high concurrency, low latency, and elastic scaling.
-  Models can be deployed as real-time inference services and batch inference tasks.
