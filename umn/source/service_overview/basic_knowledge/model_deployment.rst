:original_name: modelarts_01_0015.html

.. _modelarts_01_0015:

Model Deployment
================

ModelArts is capable of managing models and services. This allows mainstream framework images and models from multiple vendors to be managed in a unified manner.

Generally, AI model deployment and large-scale implementation are complex.


.. figure:: /_static/images/en-us_image_0000001910019742.png
   :alt: **Figure 1** Process of deploying a model

   **Figure 1** Process of deploying a model

-  The real-time inference service features high concurrency, low latency, and elastic scaling, and supports multi-model gray release and A/B testing.
-  ModelArts is optimized based on the high-performance AI inference chip Ascend 310. It can process PBs of inference data within a single day, publish over 1 million inference APIs on the cloud, and control inference network latency to milliseconds.
